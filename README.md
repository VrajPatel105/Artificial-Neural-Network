# Artificial-Neural-Network
Covering ANN including the math
Topics Covered:
  - Deep Learning introduction
  - Machine learning VS Deep learning

  - Perceptron
      - Perceptron Trick
      - Different Loss Functions
      - Multi Layer Perceptron (MLP)
          - Ways to improve overall output of the model
          - MLP Notation

    - Forward Propagation (How the data flows forward in a model while training)
        - Covering the whole math behind forward propogation
    - Back Propagation
        - Step by Step Implementation
            - Initializing values for weights and biases
            - Selecting a point (usually random point is chosen)
            - Choosing a Loss Function
            - Updating the weights and biases using Back Propagation
              - Finding all the values for all the terms for gradient descent
         - Regression and Classification Problem (intro)
         - Main Intuition and covering few questions
      - Convergence
      - Memoization
      - Different Types of Gradient Descent
          - Stochastic GD
          - Batch GD
          - Mini-Batch GD
      - Vanishing Gradient Problem
